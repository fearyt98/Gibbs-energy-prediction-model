{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install matplotlib \n",
    "%pip install seaborn\n",
    "%pip install numpy \n",
    "%pip install pandas \n",
    "%pip install pycalphad\n",
    "%pip install tensorflow\n",
    "%pip install scikit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools as itr\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn import preprocessing\n",
    "from pycalphad import Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Database('')\n",
    "main_phases = np.unique(list(db.phases.keys()))\n",
    "main_phases"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial work with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat(\n",
    "    [pd.read_csv('test.csv', sep=',', names=['t','materials','conc','G','NP', 'Phases']), \n",
    "    pd.read_csv('test.csv', sep=',', names=['t','materials','conc','G','NP', 'Phases'])])\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>G</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.445200e+06</td>\n",
       "      <td>9.289152e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.648000e+03</td>\n",
       "      <td>-1.212915e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.851752e+02</td>\n",
       "      <td>8.265972e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.980000e+02</td>\n",
       "      <td>-4.517854e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.730000e+02</td>\n",
       "      <td>-1.772967e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.648000e+03</td>\n",
       "      <td>-1.078914e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.323000e+03</td>\n",
       "      <td>-5.228421e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.998000e+03</td>\n",
       "      <td>2.337154e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  t             G\n",
       "count  9.445200e+06  9.289152e+06\n",
       "mean   1.648000e+03 -1.212915e+05\n",
       "std    7.851752e+02  8.265972e+04\n",
       "min    2.980000e+02 -4.517854e+05\n",
       "25%    9.730000e+02 -1.772967e+05\n",
       "50%    1.648000e+03 -1.078914e+05\n",
       "75%    2.323000e+03 -5.228421e+04\n",
       "max    2.998000e+03  2.337154e+04"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case there are data on phases with dependent Gibbs energy\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "enc_phs = pd.read_csv('test.csv', sep=',', names=['Enc_ph_1', 'Enc_ph_2', 'Enc_ph_3']) \n",
    "data = pd.concat([data, enc_phs], axis=1)\n",
    "data.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9283784, 9)\n",
      "      t     materials                   conc            G  \\\n",
      "1   298  ('LI', 'BE')                 [0.05] -8525.898817   \n",
      "2   298  ('LI', 'BE')  [0.07500000000000001] -8379.036561   \n",
      "3   298  ('LI', 'BE')                  [0.1] -8232.174305   \n",
      "4   298  ('LI', 'BE')                [0.125] -8085.312049   \n",
      "5   298  ('LI', 'BE')  [0.15000000000000002] -7938.449794   \n",
      "6   298  ('LI', 'BE')  [0.17500000000000002] -7791.587538   \n",
      "7   298  ('LI', 'BE')                  [0.2] -7644.725283   \n",
      "8   298  ('LI', 'BE')                [0.225] -7497.863027   \n",
      "9   298  ('LI', 'BE')                 [0.25] -7351.000771   \n",
      "10  298  ('LI', 'BE')                [0.275] -7204.138516   \n",
      "\n",
      "                                                NP  \\\n",
      "1   [0.07734289226638622, 0.9226571077335307, nan]   \n",
      "2    [0.1546857846722567, 0.8453142153270212, nan]   \n",
      "3    [0.2320286768280203, 0.7679713231721393, nan]   \n",
      "4   [0.30937156948554245, 0.6906284305195832, nan]   \n",
      "5    [0.38671446130762044, 0.613285538692424, nan]   \n",
      "6   [0.46405735356679645, 0.5359426464332764, nan]   \n",
      "7    [0.5414002458392855, 0.4585997541611684, nan]   \n",
      "8    [0.6187431380872739, 0.3812568619127095, nan]   \n",
      "9   [0.6960860303507753, 0.30391396964935324, nan]   \n",
      "10  [0.7734289226075222, 0.22657107739227325, nan]   \n",
      "\n",
      "                        Phases  Enc_ph_1  Enc_ph_2  Enc_ph_3  \n",
      "1   ['LIQUID', 'GALI_B32', '']      1442      1162         0  \n",
      "2   ['LIQUID', 'GALI_B32', '']      1442      1162         0  \n",
      "3   ['LIQUID', 'GALI_B32', '']      1442      1162         0  \n",
      "4   ['LIQUID', 'GALI_B32', '']      1442      1162         0  \n",
      "5   ['LIQUID', 'GALI_B32', '']      1442      1162         0  \n",
      "6   ['LIQUID', 'GALI_B32', '']      1442      1162         0  \n",
      "7   ['LIQUID', 'GALI_B32', '']      1442      1162         0  \n",
      "8   ['LIQUID', 'GALI_B32', '']      1442      1162         0  \n",
      "9   ['LIQUID', 'GALI_B32', '']      1442      1162         0  \n",
      "10  ['LIQUID', 'GALI_B32', '']      1442      1162         0  \n"
     ]
    }
   ],
   "source": [
    "data = data.drop_duplicates().reset_index(drop=True)\n",
    "data = data.dropna(axis=0)\n",
    "print(data.shape)\n",
    "print(data.head(10))\n",
    "metals = (\n",
    "        'LI','BE','NA','MG','AL','K','CA','SC','TI','V','CR','MN','FE',\n",
    "        'CO','NI','CU','ZN','GA','Y','ZR','NB','MO','TC',\n",
    "        'RH','PD','AG','CD','IN','SN','BA','LA','CE','PR','ND','PM','SM','EU',\n",
    "        'GD','TB','DY','HO','ER','HF','TA','W','RE','OS','IR',\n",
    "        'PT','AU','HG','TL','PB','BI', 'C', \"SI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['G'] == 0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data for training neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_phases = np.append(main_phases, '')\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "label_encoder.fit(main_phases)\n",
    "print(list(label_encoder.classes_).sort(reverse=True))\n",
    "\n",
    "t = np.asarray(data['t'])\n",
    "materials = np.zeros(shape=(len(data['materials'])), dtype=tuple)\n",
    "concentration = np.zeros(shape=(len(data['conc'])), dtype=tuple)\n",
    "phases_array = np.zeros(shape=(len(data['Phases'])), dtype=np.ndarray)\n",
    "\n",
    "for id, item in enumerate(data['materials']):\n",
    "   materials[id] = tuple(item.replace('(','').replace(')','').replace(\"'\",'').replace(\" \",'').split(\",\"))\n",
    "\n",
    "for id, item in enumerate(data['conc']):\n",
    "   concentration[id] = (np.round_(1 - float(item.replace('[','').replace(']','').replace(\"'\",'')), 3), \n",
    "                        np.round_(float(item.replace('[','').replace(']','').replace(\"'\",'')), 3))\n",
    "   \n",
    "target_nn_classes = 0      \n",
    "\n",
    "if 'Enc_ph_1' in data.columns:\n",
    "   for id, _ in enumerate(data['Phases']):\n",
    "      classes = np.zeros(shape=(len(label_encoder.classes_)), dtype=int)\n",
    "      classes[data['Enc_ph_1'].astype(int)] = 1\n",
    "      classes[data['Enc_ph_2'].astype(int)] = 1\n",
    "      classes[data['Enc_ph_3'].astype(int)] = 1\n",
    "      phases_array[id] = np.asarray(classes)\n",
    "   target_nn_classes = np.asarray(phases_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_nn_numeric_rows = np.zeros(shape=(len(data['materials']), (1+len(metals))))\n",
    "target_nn_rows = np.asarray(data['G'])\n",
    "\n",
    "for id, item in enumerate(concentration):\n",
    "    training_nn_numeric_rows[id][0] = t[id]\n",
    "    f_item_id = metals.index(materials[id][0])\n",
    "    s_item_id = metals.index(materials[id][1])\n",
    "    training_nn_numeric_rows[id][f_item_id+1] = item[0]\n",
    "    training_nn_numeric_rows[id][s_item_id+1] = item[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation on ternary systems data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del materials, concentration, t\n",
    "\n",
    "data = pd.read_csv('test.csv', sep=',', names=['t','materials','conc','G','NP', 'Phases'], engine=\"python\", encoding='utf-8', on_bad_lines='warn')\n",
    "data['G'] = data['G'].fillna(0)\n",
    "data = data[0:1500000]\n",
    "del data['NP'], data['Phases']\n",
    "print(data)\n",
    "\n",
    "valid_target_nn_rows = np.asarray(data['G'])\n",
    "\n",
    "metals = (\n",
    "        'LI','BE','NA','MG','AL','K','CA','SC','TI','V','CR','MN','FE',\n",
    "        'CO','NI','CU','ZN','GA','Y','ZR','NB','MO','TC',\n",
    "        'RH','PD','AG','CD','IN','SN','BA','LA','CE','PR','ND','PM','SM','EU',\n",
    "        'GD','TB','DY','HO','ER','HF','TA','W','RE','OS','IR',\n",
    "        'PT','AU','HG','TL','PB','BI', 'C', \"SI\")\n",
    "\n",
    "t = np.round_(np.asarray(data['t']), 2)\n",
    "materials = np.zeros(shape=(len(data['materials'])), dtype=tuple)\n",
    "concentration = np.zeros(shape=(len(data['conc'])), dtype=tuple)\n",
    "\n",
    "for id, item in enumerate(data['materials']):\n",
    "    materials[id] = tuple(item.replace('(','').replace(')','').replace(\"'\",'').replace(\" \",'').split(\",\"))\n",
    "\n",
    "for id, item in enumerate(data['conc']):\n",
    "    item = item.replace('[','').replace(']','').replace(\"'\",'').split(',')\n",
    "    concentration[id] = (np.round_(1 - (float(item[0])+float(item[1])), 1),\n",
    "                        np.round_(float(item[0]), 1), \n",
    "                        np.round_(float(item[1]), 1))\n",
    "\n",
    "training_nn_numeric_rows_valid = np.zeros(shape=(len(data['materials']), (1+len(metals))))\n",
    "\n",
    "for id, item in enumerate(concentration):\n",
    "    training_nn_numeric_rows_valid[id][0] = t[id]\n",
    "    f_item_id = metals.index(materials[id][0])\n",
    "    s_item_id = metals.index(materials[id][1])\n",
    "    th_item_id = metals.index(materials[id][2])\n",
    "    training_nn_numeric_rows_valid[id][f_item_id+1] = item[0]\n",
    "    training_nn_numeric_rows_valid[id][s_item_id+1] = item[1]\n",
    "    training_nn_numeric_rows_valid[id][th_item_id+1] = item[2]\n",
    "\n",
    "del data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def r2_score(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(training_nn_numeric_rows.shape[1]*2, activation='ReLU', kernel_initializer='random_normal', bias_initializer='zeros'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(training_nn_numeric_rows.shape[1]*2, activation='ReLU', kernel_initializer='random_normal', bias_initializer='zeros'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(training_nn_numeric_rows.shape[1]*2, activation='ReLU', kernel_initializer='random_normal', bias_initializer='zeros'))\n",
    "model.add(Dense(1, activation=\"linear\"))\n",
    "\n",
    "model.build(input_shape=(training_nn_numeric_rows.shape[0], training_nn_numeric_rows.shape[1]))\n",
    "model.summary()\n",
    "\n",
    "lr = 0.0001\n",
    "optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", metrics=['mae', r2_score], optimizer=optimizer)\n",
    "hist = model.fit(x=training_nn_numeric_rows, y=target_nn_rows, epochs=15, shuffle=True, validation_split=0.2)\n",
    "model.save('test_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('DNN model loss')\n",
    "plt.ylabel('Loss, MSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.savefig('dnn_15ep_0.2valid.png', dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating synthetic data for performance testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rand\n",
    "from numpy.random import dirichlet as dr\n",
    "\n",
    "syntetic_pred_lst = np.zeros(shape=(1000000, (1+len(metals))))\n",
    "\n",
    "for i in range(0, 1000000, 1):\n",
    "    syntetic_pred_lst[i][0] = rand.randint(299, 3000)\n",
    "    temp = dr(np.ones(12),size=1)\n",
    "    syntetic_pred_lst[i][1] = temp[0][0]\n",
    "    syntetic_pred_lst[i][2] = temp[0][1]\n",
    "    syntetic_pred_lst[i][3] = temp[0][2]\n",
    "    syntetic_pred_lst[i][4] = temp[0][3]\n",
    "    syntetic_pred_lst[i][5] = temp[0][4]\n",
    "    syntetic_pred_lst[i][6] = temp[0][5]\n",
    "    syntetic_pred_lst[i][7] = temp[0][6]\n",
    "    syntetic_pred_lst[i][8] = temp[0][7]\n",
    "    syntetic_pred_lst[i][9] = temp[0][8]\n",
    "    syntetic_pred_lst[i][10] = temp[0][9]\n",
    "    syntetic_pred_lst[i][11] = temp[0][10]\n",
    "    syntetic_pred_lst[i][12] = temp[0][11]\n",
    "\n",
    "syntetic_pred_lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "def r2_score(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "dependencies = {\n",
    "    'r2_score': r2_score\n",
    "}\n",
    "test = load_model('test_model.h5', custom_objects=dependencies)\n",
    "test.predict(syntetic_pred_lst)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LayerNormalization, Conv1D, Flatten, MaxPooling1D\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def r2_score(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "training_nn_rows = training_nn_numeric_rows.reshape(training_nn_numeric_rows.shape[0], training_nn_numeric_rows.shape[1], 1)\n",
    "print(training_nn_rows.shape)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(32, 2, activation=\"ReLU\", strides=1, padding=\"same\"))\n",
    "model.add(MaxPooling1D(pool_size=2, strides=1, padding='valid')) \n",
    "model.add(Dropout(0.1))\n",
    "model.add(Conv1D(16, 2, activation=\"ReLU\", strides=1, padding=\"same\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='ReLU', kernel_initializer='random_normal', bias_initializer='zeros'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(16, activation='ReLU', kernel_initializer='random_normal', bias_initializer='zeros'))\n",
    "model.add(Dense(8, activation='ReLU', kernel_initializer='random_normal', bias_initializer='zeros'))\n",
    "model.add(Dense(1, activation=\"linear\"))\n",
    "\n",
    "model.build(input_shape=(training_nn_rows.shape[0], training_nn_rows.shape[1], 1))\n",
    "model.summary()\n",
    "\n",
    "lr = 0.0001\n",
    "optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", metrics=['mae', r2_score], optimizer=optimizer)\n",
    "# optimal epochs - 5\n",
    "hist = model.fit(x=training_nn_rows, y=target_nn_rows, epochs=8, shuffle=True, validation_split=0.2) \n",
    "model.save('test_model.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not an actual chart, just an example of model overfitting at 8 epochs\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('CNN model loss')\n",
    "plt.ylabel('Loss, MSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.savefig('cnn_15ep_0.2valid_8ep.png', dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model validation works"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.metrics import r2_score as r2s, mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "def r2_score(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "dependencies = {\n",
    "    'r2_score': r2_score\n",
    "}\n",
    "model_cnn = load_model('../models/cnn_model_5ep_0.2val_final.h5', custom_objects=dependencies)\n",
    "model_dnn = load_model('../models/dnn_model_15ep_0.2val_final.h5', custom_objects=dependencies)\n",
    "\n",
    "\n",
    "data = pd.concat(\n",
    "    [pd.read_csv('../test.csv', sep=',', names=['t','materials','conc','G','NP', 'Phases']), \n",
    "    pd.read_csv('../test.csv', sep=',', names=['t','materials','conc','G','NP', 'Phases'])\n",
    "    ])\n",
    "data = data.dropna(axis=0)\n",
    "del data['NP'], data['Phases']\n",
    "data = data[data['materials'] == \"('BE', 'FE')\"]\n",
    "\n",
    "valid_target_nn_rows = np.asarray(data['G'])\n",
    "\n",
    "metals = (\n",
    "        'LI','BE','NA','MG','AL','K','CA','SC','TI','V','CR','MN','FE',\n",
    "        'CO','NI','CU','ZN','GA','Y','ZR','NB','MO','TC',\n",
    "        'RH','PD','AG','CD','IN','SN','BA','LA','CE','PR','ND','PM','SM','EU',\n",
    "        'GD','TB','DY','HO','ER','HF','TA','W','RE','OS','IR',\n",
    "        'PT','AU','HG','TL','PB','BI', 'C', \"SI\")\n",
    "\n",
    "t = np.asarray(data['t'])\n",
    "materials = np.zeros(shape=(len(data['materials'])), dtype=tuple)\n",
    "concentration = np.zeros(shape=(len(data['conc'])), dtype=tuple)\n",
    "\n",
    "for id, item in enumerate(data['materials']):\n",
    "   materials[id] = tuple(item.replace('(','').replace(')','').replace(\"'\",'').replace(\" \",'').split(\",\"))\n",
    "\n",
    "for id, item in enumerate(data['conc']):\n",
    "   concentration[id] = (np.round_(1 - float(item.replace('[','').replace(']','').replace(\"'\",'')), 3), \n",
    "                        np.round_(float(item.replace('[','').replace(']','').replace(\"'\",'')), 3))\n",
    "\n",
    "\n",
    "training_nn_numeric_rows_valid = np.zeros(shape=(len(data['materials']), (1+len(metals))))\n",
    "\n",
    "for id, item in enumerate(concentration):\n",
    "    training_nn_numeric_rows_valid[id][0] = t[id]\n",
    "    f_item_id = metals.index(materials[id][0])\n",
    "    s_item_id = metals.index(materials[id][1])\n",
    "    training_nn_numeric_rows_valid[id][f_item_id+1] = item[0]\n",
    "    training_nn_numeric_rows_valid[id][s_item_id+1] = item[1]\n",
    "\n",
    "valid_predict_dnn = model_dnn.predict(x=training_nn_numeric_rows_valid)\n",
    "valid_predict_cnn = model_cnn.predict(x=training_nn_numeric_rows_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2s(valid_target_nn_rows, valid_predict_cnn))\n",
    "print(mean_squared_error(valid_target_nn_rows, valid_predict_cnn))\n",
    "print(np.sqrt(mean_squared_error(valid_target_nn_rows, valid_predict_cnn)))\n",
    "print(mean_absolute_error(valid_target_nn_rows, valid_predict_cnn))\n",
    "print(mean_absolute_percentage_error(valid_target_nn_rows, valid_predict_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10, 10), dpi=1000)\n",
    "ax.set_yticks(range(298, 3000, 325))\n",
    "ax.set_xticks(range(0, int(np.minimum(np.min(valid_target_nn_rows), np.min(valid_predict_dnn))), -25000))\n",
    "ax.set_ylabel('T, K', fontsize=20)\n",
    "ax.set_xlabel('G, J', fontsize=20)\n",
    "f.suptitle('Na-V system (DNN)', fontsize=20)\n",
    "sns.scatterplot(x=valid_predict_dnn.flatten(), y=t, linewidth=0, color=\"#F20587\", marker='s', s = 100, ax=ax)\n",
    "sns.scatterplot(x=valid_target_nn_rows.flatten(), y=t, linewidth=0, color=\"#6AFC98\", ax=ax,  s = 100, marker='s')\n",
    "plt.legend(loc='lower left', labels=['Predicted values', 'Original values'], fontsize=15, markerscale=2)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.savefig('Figure 11 - dnn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(figsize=(12, 10), dpi=300)\n",
    "ax.set_yticks(range(298, 3000, 325))\n",
    "ax.set_xticks(range(0, int(np.minimum(np.min(valid_target_nn_rows), np.min(valid_predict_cnn))), -25000))\n",
    "ax.set_ylabel('T, K', fontsize=20)\n",
    "ax.set_xlabel('G, J', fontsize=20)\n",
    "f.suptitle('Be-Fe system (CNN)', fontsize=20)\n",
    "sns.scatterplot(x=valid_predict_cnn.flatten(), y=t, linewidth=0, color=\"#0099DD\", marker='s', s = 100, ax=ax)\n",
    "sns.scatterplot(x=valid_target_nn_rows.flatten(), y=t, linewidth=0, color=\"#FF9933\", ax=ax,  s = 100, marker='s')\n",
    "plt.legend(loc='lower left', labels=['Predicted values', 'Original values'], fontsize=15, markerscale=2)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.savefig('../images/cnn_binary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2s(valid_target_nn_rows, valid_predict_nn_rows))\n",
    "print(mean_squared_error(valid_target_nn_rows, valid_predict_nn_rows))\n",
    "print(np.sqrt(mean_squared_error(valid_target_nn_rows, valid_predict_nn_rows)))\n",
    "print(mean_absolute_error(valid_target_nn_rows, valid_predict_nn_rows))\n",
    "print(mean_absolute_percentage_error(valid_target_nn_rows, valid_predict_nn_rows))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ternary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.metrics import r2_score as r2s, mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "def r2_score(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "dependencies = {\n",
    "    'r2_score': r2_score\n",
    "}\n",
    "model_cnn = load_model('../models/cnn_model_5ep_0.2val_final.h5', custom_objects=dependencies)\n",
    "model_dnn = load_model('../models/dnn_model_15ep_0.2val_final.h5', custom_objects=dependencies)\n",
    "\n",
    "data = pd.read_csv('../test.csv', sep=',', names=['t','materials','conc','G','NP', 'Phases'], engine=\"python\", encoding='utf-8', on_bad_lines='warn')\n",
    "data = data.dropna(axis=0)\n",
    "del data['NP'], data['Phases']\n",
    "data = data[data['materials'] == \"('MG', 'TI', 'ZN')\"]\n",
    "print(data)\n",
    "\n",
    "valid_target_nn_rows = np.asarray(data['G'])\n",
    "\n",
    "metals = (\n",
    "        'LI','BE','NA','MG','AL','K','CA','SC','TI','V','CR','MN','FE',\n",
    "        'CO','NI','CU','ZN','GA','Y','ZR','NB','MO','TC',\n",
    "        'RH','PD','AG','CD','IN','SN','BA','LA','CE','PR','ND','PM','SM','EU',\n",
    "        'GD','TB','DY','HO','ER','HF','TA','W','RE','OS','IR',\n",
    "        'PT','AU','HG','TL','PB','BI', 'C', \"SI\")\n",
    "\n",
    "t = np.round_(np.asarray(data['t']), 2)\n",
    "materials = np.zeros(shape=(len(data['materials'])), dtype=tuple)\n",
    "concentration = np.zeros(shape=(len(data['conc'])), dtype=tuple)\n",
    "\n",
    "for id, item in enumerate(data['materials']):\n",
    "    materials[id] = tuple(item.replace('(','').replace(')','').replace(\"'\",'').replace(\" \",'').split(\",\"))\n",
    "\n",
    "for id, item in enumerate(data['conc']):\n",
    "    item = item.replace('[','').replace(']','').replace(\"'\",'').split(',')\n",
    "    concentration[id] = (np.round_(1 - (float(item[0])+float(item[1])), 1),\n",
    "                        np.round_(float(item[0]), 1), \n",
    "                        np.round_(float(item[1]), 1))\n",
    "\n",
    "\n",
    "training_nn_numeric_rows_valid = np.zeros(shape=(len(data['materials']), (1+len(metals)))) \n",
    "\n",
    "for id, item in enumerate(concentration):\n",
    "    training_nn_numeric_rows_valid[id][0] = t[id]\n",
    "    f_item_id = metals.index(materials[id][0])\n",
    "    s_item_id = metals.index(materials[id][1])\n",
    "    th_item_id = metals.index(materials[id][2])\n",
    "    training_nn_numeric_rows_valid[id][f_item_id+1] = item[0]\n",
    "    training_nn_numeric_rows_valid[id][s_item_id+1] = item[1]\n",
    "    training_nn_numeric_rows_valid[id][th_item_id+1] = item[2]\n",
    "\n",
    "valid_predict_dnn = model_dnn.predict(x=training_nn_numeric_rows_valid)\n",
    "valid_predict_cnn = model_cnn.predict(x=training_nn_numeric_rows_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2s(valid_target_nn_rows, valid_predict_dnn))\n",
    "print(mean_squared_error(valid_target_nn_rows, valid_predict_dnn))\n",
    "print(np.sqrt(mean_squared_error(valid_target_nn_rows, valid_predict_dnn)))\n",
    "print(mean_absolute_error(valid_target_nn_rows, valid_predict_dnn))\n",
    "print(mean_absolute_percentage_error(valid_target_nn_rows, valid_predict_dnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(figsize=(35, 25), dpi=300)\n",
    "ax.set_yticks(range(298, 3000, 200))\n",
    "ax.set_xticks(range(0, int(np.minimum(np.min(valid_target_nn_rows), np.min(valid_predict_dnn))), -25000))\n",
    "ax.set_ylabel('T, K', fontsize=40)\n",
    "ax.set_xlabel('G, J', fontsize=40)\n",
    "f.suptitle('Mg-Al-ZN system (DNN)', fontsize=45)\n",
    "sns.scatterplot(x=valid_predict_dnn.flatten(), y=t, linewidth=0, color=\"#0099DD\", marker='s', s = 100, ax=ax)\n",
    "sns.scatterplot(x=valid_target_nn_rows.flatten(), y=t, linewidth=0, color=\"#FF9933\", ax=ax,  s = 100, marker='s')\n",
    "plt.legend(loc='lower left', labels=['Predicted values', 'Original values'], fontsize=40, markerscale=3)\n",
    "plt.xticks(fontsize=30)\n",
    "plt.yticks(fontsize=30)\n",
    "plt.savefig('../images/dnn_ternary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(figsize=(35, 25), dpi=600)\n",
    "ax.set_yticks(range(298, 3000, 200))\n",
    "ax.set_xticks(range(0, int(np.minimum(np.min(valid_target_nn_rows), np.min(valid_predict_cnn))), -25000))\n",
    "ax.set_ylabel('T, K', fontsize=40)\n",
    "ax.set_xlabel('G, J', fontsize=40)\n",
    "f.suptitle('Mg-Sc-Ta system (CNN)', fontsize=45)\n",
    "sns.scatterplot(x=valid_predict_cnn.flatten(), y=t, linewidth=0, color=\"#F20587\", marker='s', s = 100, ax=ax)\n",
    "sns.scatterplot(x=valid_target_nn_rows.flatten(), y=t, linewidth=0, color=\"#6AFC98\", ax=ax,  s = 100, marker='s')\n",
    "plt.legend(loc='lower left', labels=['Predicted values', 'Original values'], fontsize=40, markerscale=3)\n",
    "plt.xticks(fontsize=30)\n",
    "plt.yticks(fontsize=30)\n",
    "plt.savefig('Figure 12 - cnn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2s(valid_target_nn_rows, valid_predict_nn_rows))\n",
    "print(mean_squared_error(valid_target_nn_rows, valid_predict_nn_rows))\n",
    "print(np.sqrt(mean_squared_error(valid_target_nn_rows, valid_predict_nn_rows)))\n",
    "print(mean_absolute_error(valid_target_nn_rows, valid_predict_nn_rows))\n",
    "print(mean_absolute_percentage_error(valid_target_nn_rows, valid_predict_nn_rows))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare on binary systems data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.metrics import r2_score as r2s, mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "def r2_score(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "dependencies = {\n",
    "    'r2_score': r2_score\n",
    "}\n",
    "model_cnn = load_model('models/cnn_model_5ep_0.2val_final.h5', custom_objects=dependencies)\n",
    "model_dnn = load_model('models/dnn_model_15ep_0.2val_final.h5', custom_objects=dependencies)\n",
    "\n",
    "\n",
    "data = pd.concat(\n",
    "    [pd.read_csv('data samples/valid_t300_w0.25.csv', sep=',', names=['t','materials','conc','G','NP', 'Phases']), \n",
    "    pd.read_csv('data samples/valid_325_w0.18.csv', sep=',', names=['t','materials','conc','G','NP', 'Phases'])])\n",
    "del data['NP'], data['Phases']\n",
    "\n",
    "valid_target_nn_rows = np.asarray(data['G'])\n",
    "\n",
    "metals = (\n",
    "        'LI','BE','NA','MG','AL','K','CA','SC','TI','V','CR','MN','FE',\n",
    "        'CO','NI','CU','ZN','GA','Y','ZR','NB','MO','TC',\n",
    "        'RH','PD','AG','CD','IN','SN','BA','LA','CE','PR','ND','PM','SM','EU',\n",
    "        'GD','TB','DY','HO','ER','HF','TA','W','RE','OS','IR',\n",
    "        'PT','AU','HG','TL','PB','BI', 'C', \"SI\")\n",
    "\n",
    "t = np.asarray(data['t'])\n",
    "materials = np.zeros(shape=(len(data['materials'])), dtype=tuple)\n",
    "concentration = np.zeros(shape=(len(data['conc'])), dtype=tuple)\n",
    "\n",
    "for id, item in enumerate(data['materials']):\n",
    "   materials[id] = tuple(item.replace('(','').replace(')','').replace(\"'\",'').replace(\" \",'').split(\",\"))\n",
    "\n",
    "for id, item in enumerate(data['conc']):\n",
    "   concentration[id] = (np.round_(1 - float(item.replace('[','').replace(']','').replace(\"'\",'')), 3), \n",
    "                        np.round_(float(item.replace('[','').replace(']','').replace(\"'\",'')), 3))\n",
    "\n",
    "\n",
    "training_nn_numeric_rows_valid = np.zeros(shape=(len(data['materials']), (1+len(metals))))\n",
    "\n",
    "for id, item in enumerate(concentration):\n",
    "    training_nn_numeric_rows_valid[id][0] = t[id]\n",
    "    f_item_id = metals.index(materials[id][0])\n",
    "    s_item_id = metals.index(materials[id][1])\n",
    "    training_nn_numeric_rows_valid[id][f_item_id+1] = item[0]\n",
    "    training_nn_numeric_rows_valid[id][s_item_id+1] = item[1]\n",
    "\n",
    "valid_predict_dnn = model_dnn.predict(x=training_nn_numeric_rows_valid)\n",
    "valid_predict_cnn = model_cnn.predict(x=training_nn_numeric_rows_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(valid_predict_dnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "\n",
    "max_min = 0\n",
    "\n",
    "if np.min(valid_predict_dnn) < np.min(valid_predict_cnn):\n",
    "    max_min = np.min(valid_predict_dnn)\n",
    "else:\n",
    "    max_min = np.min(valid_predict_cnn)\n",
    "max_min = np.round_(max_min)\n",
    "\n",
    "fig = plt.figure(figsize=(50,20), dpi=600)\n",
    "ax = fig.subplots(1, 2)\n",
    "ax[0].set_yticks(range(298, 3000, 300))\n",
    "ax[0].set_xticks(range(0, int(max_min), -20000))\n",
    "ax[0].set_xlim(int(max_min), 100)\n",
    "\n",
    "ax[1].set_yticks(range(298, 3000, 300))\n",
    "ax[1].set_xticks(range(0, int(max_min), -20000)) \n",
    "ax[1].set_xlim(int(max_min), 100)\n",
    "\n",
    "ax[0].tick_params(axis='both', which='both', labelsize=30)\n",
    "ax[1].tick_params(axis='both', which='both', labelsize=30)\n",
    "\n",
    "ax[0].set_ylabel('T, K', fontsize=40)\n",
    "ax[1].set_ylabel('T, K', fontsize=40)\n",
    "\n",
    "ax[0].set_xlabel('G, J (1e5)', fontsize=40)\n",
    "ax[1].set_xlabel('G, J (1e5)', fontsize=40)\n",
    "\n",
    "ax[0].ticklabel_format(style='sci', axis='x', scilimits=(0,0))\n",
    "ax[1].ticklabel_format(style='sci', axis='x', scilimits=(0,0))\n",
    "\n",
    "fig.suptitle('On the left DNN, right CNN model', fontsize=60)\n",
    "\n",
    "sns.histplot(x=valid_predict_dnn.flatten(), y= t, color=\"#F20587\", bins=20, ax=ax[0])\n",
    "sns.histplot(x=valid_predict_cnn.flatten(), y= t, color=\"#6AFC98\", bins=20, ax=ax[1])\n",
    "sns.despine(left = False)\n",
    "\n",
    "plt.savefig(\"dnn_cnn.png\", dpi=600)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "\n",
    "max_min = np.min(valid_predict_dnn)\n",
    "\n",
    "if np.min(valid_target_nn_rows) < max_min: \n",
    "    max_min = np.min(valid_target_nn_rows)\n",
    "\n",
    "max_min = np.round_(max_min)\n",
    "\n",
    "fig = plt.figure(figsize=(50,20), dpi=600)\n",
    "ax = fig.subplots(1, 2)\n",
    "ax[0].set_yticks(range(298, 3000, 300))\n",
    "ax[0].set_xticks(range(0, int(max_min), -20000))\n",
    "ax[0].set_xlim(int(max_min), 100)\n",
    "\n",
    "ax[1].set_yticks(range(298, 3000, 300))\n",
    "ax[1].set_xticks(range(0, int(max_min), -20000)) \n",
    "ax[1].set_xlim(int(max_min), 100)\n",
    "\n",
    "ax[0].tick_params(axis='both', which='both', labelsize=30)\n",
    "ax[1].tick_params(axis='both', which='both', labelsize=30)\n",
    "\n",
    "ax[0].set_ylabel('T, K', fontsize=40)\n",
    "ax[1].set_ylabel('T, K', fontsize=40)\n",
    "\n",
    "ax[0].set_xlabel('G, J (1e5)', fontsize=40)\n",
    "ax[1].set_xlabel('G, J (1e5)', fontsize=40)\n",
    "\n",
    "ax[0].ticklabel_format(style='sci', axis='x', scilimits=(0,0))\n",
    "ax[1].ticklabel_format(style='sci', axis='x', scilimits=(0,0))\n",
    "\n",
    "fig.suptitle('On the left, the original values, right DNN model', fontsize=60)\n",
    "\n",
    "sns.histplot(x=valid_target_nn_rows.flatten(), y= t, color=\"#F20587\", bins=20, ax=ax[0])\n",
    "sns.histplot(x=valid_predict_dnn.flatten(), y= t, color=\"#2E038C\", bins=20, ax=ax[1])\n",
    "sns.despine(left = False)\n",
    "\n",
    "plt.savefig(\"dnn.png\", dpi=600)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "\n",
    "max_min = np.min(valid_predict_cnn)\n",
    "\n",
    "if np.min(valid_target_nn_rows) < max_min: \n",
    "    max_min = np.min(valid_target_nn_rows)\n",
    "\n",
    "max_min = np.round_(max_min)\n",
    "\n",
    "fig = plt.figure(figsize=(50,20), dpi=600)\n",
    "ax = fig.subplots(1, 2)\n",
    "ax[0].set_yticks(range(298, 3000, 300))\n",
    "ax[0].set_xticks(range(0, int(max_min), -20000))\n",
    "ax[0].set_xlim(int(max_min), 100)\n",
    "\n",
    "ax[1].set_yticks(range(298, 3000, 300))\n",
    "ax[1].set_xticks(range(0, int(max_min), -20000)) \n",
    "ax[1].set_xlim(int(max_min), 100)\n",
    "\n",
    "ax[0].tick_params(axis='both', which='both', labelsize=30)\n",
    "ax[1].tick_params(axis='both', which='both', labelsize=30)\n",
    "\n",
    "ax[0].set_ylabel('T, K', fontsize=40)\n",
    "ax[1].set_ylabel('T, K', fontsize=40)\n",
    "\n",
    "ax[0].set_xlabel('G, J (1e5)', fontsize=40)\n",
    "ax[1].set_xlabel('G, J (1e5)', fontsize=40)\n",
    "\n",
    "ax[0].ticklabel_format(style='sci', axis='x', scilimits=(0,0))\n",
    "ax[1].ticklabel_format(style='sci', axis='x', scilimits=(0,0))\n",
    "\n",
    "fig.suptitle('On the left, the original values, right CNN model', fontsize=60)\n",
    "\n",
    "sns.histplot(x=valid_target_nn_rows.flatten(), y= t, color=\"#F20587\", bins=20, ax=ax[0])\n",
    "sns.histplot(x=valid_predict_cnn.flatten(), y= t, color=\"#2E038C\", bins=20, ax=ax[1])\n",
    "sns.despine(left = False)\n",
    "\n",
    "plt.savefig(\"cnn.png\", dpi=600)  \n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another validation on ternary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.metrics import r2_score as r2s, mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "def r2_score(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "dependencies = {\n",
    "    'r2_score': r2_score\n",
    "}\n",
    "model = load_model('../models/cnn_model_5ep_0.2val_final.h5', custom_objects=dependencies)\n",
    "\n",
    "data = pd.concat(\n",
    "    [pd.read_csv('test.csv', sep=',', names=['t','materials','conc','G','NP', 'Phases'], engine=\"python\", encoding='utf-8', on_bad_lines='warn'), \n",
    "    pd.read_csv('test.csv', sep=',', names=['t','materials','conc','G','NP', 'Phases'], engine=\"python\", encoding='utf-8', on_bad_lines='warn')])\n",
    "data['G'] = data['G'].fillna(0)\n",
    "del data['NP'], data['Phases']\n",
    "print(data)\n",
    "\n",
    "valid_target_nn_rows = np.asarray(data['G'])\n",
    "\n",
    "metals = (\n",
    "        'LI','BE','NA','MG','AL','K','CA','SC','TI','V','CR','MN','FE',\n",
    "        'CO','NI','CU','ZN','GA','Y','ZR','NB','MO','TC',\n",
    "        'RH','PD','AG','CD','IN','SN','BA','LA','CE','PR','ND','PM','SM','EU',\n",
    "        'GD','TB','DY','HO','ER','HF','TA','W','RE','OS','IR',\n",
    "        'PT','AU','HG','TL','PB','BI', 'C', \"SI\")\n",
    "\n",
    "t = np.round_(np.asarray(data['t']), 2)\n",
    "materials = np.zeros(shape=(len(data['materials'])), dtype=tuple)\n",
    "concentration = np.zeros(shape=(len(data['conc'])), dtype=tuple)\n",
    "\n",
    "for id, item in enumerate(data['materials']):\n",
    "    materials[id] = tuple(item.replace('(','').replace(')','').replace(\"'\",'').replace(\" \",'').split(\",\"))\n",
    "\n",
    "for id, item in enumerate(data['conc']):\n",
    "    item = item.replace('[','').replace(']','').replace(\"'\",'').split(',')\n",
    "    concentration[id] = (np.round_(1 - (float(item[0])+float(item[1])), 1),\n",
    "                        np.round_(float(item[0]), 1), \n",
    "                        np.round_(float(item[1]), 1))\n",
    "\n",
    "\n",
    "training_nn_numeric_rows_valid = np.zeros(shape=(len(data['materials']), (1+len(metals))))\n",
    "\n",
    "for id, item in enumerate(concentration):\n",
    "    training_nn_numeric_rows_valid[id][0] = t[id]\n",
    "    f_item_id = metals.index(materials[id][0])\n",
    "    s_item_id = metals.index(materials[id][1])\n",
    "    th_item_id = metals.index(materials[id][2])\n",
    "    training_nn_numeric_rows_valid[id][f_item_id+1] = item[0]\n",
    "    training_nn_numeric_rows_valid[id][s_item_id+1] = item[1]\n",
    "    training_nn_numeric_rows_valid[id][th_item_id+1] = item[2]\n",
    "\n",
    "\n",
    "valid_predict_nn_rows = model.predict(x=training_nn_numeric_rows_valid)\n",
    "\n",
    "print(r2s(valid_target_nn_rows, valid_predict_nn_rows))\n",
    "print(mean_squared_error(valid_target_nn_rows, valid_predict_nn_rows))\n",
    "print(mean_absolute_error(valid_target_nn_rows, valid_predict_nn_rows))\n",
    "print(mean_absolute_percentage_error(valid_target_nn_rows, valid_predict_nn_rows))\n",
    "print(len(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(50,20), dpi=150)\n",
    "ax = fig.subplots(1, 2)\n",
    "ax[0].set_yticks(range(298, 3000, 300))\n",
    "ax[0].set_xticks(range(0, -400000, -5000))\n",
    "\n",
    "ax[1].set_yticks(range(298, 3000, 300))\n",
    "ax[1].set_xticks(range(0, -400000, -5000))\n",
    "\n",
    "ax[0].tick_params(axis='y', which='major', labelsize=25)\n",
    "ax[1].tick_params(axis='y', which='major', labelsize=25)\n",
    "ax[0].set_ylabel('T, K', fontsize=25)\n",
    "\n",
    "fig.suptitle('Слева DNN модель, справа CNN модель', fontsize=50)\n",
    "\n",
    "sns.histplot(x=dnn_values.flatten(), y= t, color=\"#F20587\", bins=20, ax=ax[0])\n",
    "sns.histplot(x=valid_predict_nn_rows.flatten(), y= t, color=\"#2E038C\", bins=20, ax=ax[1])\n",
    "sns.despine(left = False)\n",
    "\n",
    "plt.savefig(\"DNN_CNN.png\")  \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
